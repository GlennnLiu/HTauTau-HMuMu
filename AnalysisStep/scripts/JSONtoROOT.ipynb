{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes to transfer the muon reco and trigger efficiency scale factors from json format to root format. It would create the root file with the same name in the same folder as the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/09\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import ROOT as rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reco efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecoSF:\n",
    "    def __init__(self,name):\n",
    "        self.file_name=name\n",
    "        self.hist_name=\"\"\n",
    "        self.data=None\n",
    "        self.__ReadJSON()\n",
    "        \n",
    "    def __ReadJSON(self):\n",
    "        f=open(self.file_name)\n",
    "        a=json.load(f)\n",
    "        self.hist_name=a.keys()[0].encode('utf-8')\n",
    "        a=a[a.keys()[0]]\n",
    "        a=a[a.keys()[0]]\n",
    "        self.data=a\n",
    "        \n",
    "    def __toBin(self,key):\n",
    "        s=key.encode('utf-8')\n",
    "        left=float(s.split(\"[\")[-1].split(\",\")[0])\n",
    "        right=float(s.split(\"]\")[0].split(\",\")[-1])\n",
    "        return left,right\n",
    "    \n",
    "    def __toBins(self,var):\n",
    "        binDict=self.data[self.data.keys()[0]]\n",
    "        for each in binDict:\n",
    "            if each['variable'].encode('utf-8')==var:\n",
    "                return np.array(each['binning'])\n",
    "        print(\"Variable {0} not found!\".format(var))\n",
    "        \n",
    "    def JSONtoROOT(self):\n",
    "        pt_bins=self.__toBins('pt')\n",
    "        eta_bins=self.__toBins('abseta')\n",
    "        hist=rt.TH2F(self.hist_name+\"_abseta_pt\",\";|#eta|;p_{T} (GeV)\",len(eta_bins)-1,eta_bins.astype(float),len(pt_bins)-1,pt_bins.astype(float))\n",
    "        hist_stat=rt.TH2F(self.hist_name+\"_abseta_pt_stat\",\";|#eta|;p_{T} (GeV)\",len(eta_bins)-1,eta_bins.astype(float),len(pt_bins)-1,pt_bins.astype(float))\n",
    "        hist_syst=rt.TH2F(self.hist_name+\"_abseta_pt_syst\",\";|#eta|;p_{T} (GeV)\",len(eta_bins)-1,eta_bins.astype(float),len(pt_bins)-1,pt_bins.astype(float))\n",
    "\n",
    "        for ipt in range(len(pt_bins)-1):\n",
    "            for ieta in range(len(eta_bins)-1):\n",
    "                pt_key=u\"pt:[{0},{1}]\".format(pt_bins[ipt],pt_bins[ipt+1])\n",
    "                eta_key=u\"abseta:[{0},{1}]\".format(eta_bins[ieta],eta_bins[ieta+1])\n",
    "                nom=self.data[eta_key][pt_key][u'value']\n",
    "                stat=self.data[eta_key][pt_key][u'stat']\n",
    "                syst=self.data[eta_key][pt_key][u'syst']\n",
    "                hist.SetBinContent(ieta+1,ipt+1,nom)\n",
    "                hist_stat.SetBinContent(ieta+1,ipt+1,nom)\n",
    "                hist_stat.SetBinError(ieta+1,ipt+1,stat)\n",
    "                hist_syst.SetBinContent(ieta+1,ipt+1,nom)\n",
    "                hist_syst.SetBinError(ieta+1,ipt+1,syst)\n",
    "\n",
    "        f_out=rt.TFile(self.file_name.replace(\"json\",\"root\"),\"recreate\")\n",
    "        f_out.cd()\n",
    "        hist.Write()\n",
    "        hist_stat.Write()\n",
    "        hist_syst.Write()\n",
    "        f_out.Write()\n",
    "        f_out.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoSF=RecoSF(\"NUM_TrackerMuons_DEN_genTracks_Z_abseta_pt.json\")\n",
    "recoSF.JSONtoROOT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrgSF:\n",
    "    def __init__(self,name):\n",
    "        self.file_name=name\n",
    "        self.hist_name={}\n",
    "        self.data={}\n",
    "        self.nInputs={}\n",
    "        self.nScheme=0\n",
    "        self.__ReadJSON()\n",
    "        \n",
    "    def __ReadJSON(self):\n",
    "        f=open(self.file_name)\n",
    "        a=json.load(f)['corrections']\n",
    "        self.nScheme=len(a)\n",
    "        for iS in range(self.nScheme):\n",
    "            self.hist_name[iS]=a[iS]['name'].encode('utf-8')\n",
    "            self.nInputs[iS]=len(a[iS]['inputs'])-1\n",
    "            self.data[iS]=a[iS]\n",
    "            \n",
    "    def __GetHist2D(self,i):\n",
    "        data=self.data[i]\n",
    "        var1=data['inputs'][0]['name'].encode('utf-8')\n",
    "        var2=data['inputs'][1]['name'].encode('utf-8')\n",
    "        data=data['data']\n",
    "        bins1=np.array(data['edges'])\n",
    "        bins2=np.array(data['content'][0]['edges'])\n",
    "        nbin1=len(bins1)-1\n",
    "        nbin2=len(bins2)-1\n",
    "        hist_name=self.hist_name[i]+\"_\"+var1+\"_\"+var2\n",
    "        hist=rt.TH2F(hist_name,\";|#eta|;p_{T} (GeV)\",nbin1,bins1,nbin2,bins2)\n",
    "        hist_stat=rt.TH2F(hist_name+\"_stat\",\";|#eta|;p_{T} (GeV)\",nbin1,bins1,nbin2,bins2)\n",
    "        hist_syst=rt.TH2F(hist_name+\"_syst\",\";|#eta|;p_{T} (GeV)\",nbin1,bins1,nbin2,bins2)\n",
    "        for i1 in range(nbin1):\n",
    "            for i2 in range(nbin2):\n",
    "                nom=data['content'][i1]['content'][i2]['content'][5]['value']\n",
    "                stat=data['content'][i1]['content'][i2]['content'][3]['value']\n",
    "                syst=data['content'][i1]['content'][i2]['content'][4]['value']\n",
    "                hist.SetBinContent(i1+1,i2+1,nom)\n",
    "                hist_stat.SetBinContent(i1+1,i2+1,nom)\n",
    "                hist_stat.SetBinError(i1+1,i2+1,stat)\n",
    "                hist_syst.SetBinContent(i1+1,i2+1,nom)\n",
    "                hist_syst.SetBinError(i1+1,i2+1,syst)\n",
    "        return hist,hist_stat,hist_syst\n",
    "        \n",
    "    def __GetHist3D(self,i):\n",
    "        data=self.data[i]\n",
    "        var1=data['inputs'][0]['name'].encode('utf-8')\n",
    "        var2=data['inputs'][1]['name'].encode('utf-8')\n",
    "        var3=data['inputs'][2]['name'].encode('utf-8')\n",
    "        data=data['data']\n",
    "        bins1=np.array(data['edges'])\n",
    "        bins2=np.array(data['content'][0]['edges'])\n",
    "        bins3=np.array(data['content'][0]['content'][0]['edges'])\n",
    "        nbin1=len(bins1)-1\n",
    "        nbin2=len(bins2)-1\n",
    "        nbin3=len(bins3)-1\n",
    "        hist_name=self.hist_name[i]+\"_\"+var1+\"_\"+var2+\"_\"+var3\n",
    "        hist=rt.TH3F(hist_name,\"charge;|#eta|;p_{T} (GeV)\",nbin1,bins1,nbin2,bins2,nbin3,bins3)\n",
    "        hist_stat=rt.TH3F(hist_name+\"_stat\",\";charge;|#eta|;p_{T} (GeV)\",nbin1,bins1,nbin2,bins2,nbin3,bins3)\n",
    "        hist_syst=rt.TH3F(hist_name+\"_syst\",\";charge;|#eta|;p_{T} (GeV)\",nbin1,bins1,nbin2,bins2,nbin3,bins3)\n",
    "        for i1 in range(nbin1):\n",
    "            for i2 in range(nbin2):\n",
    "                for i3 in range(nbin3):\n",
    "                    nom=data['content'][i1]['content'][i2]['content'][i3]['content'][5]['value']\n",
    "                    stat=data['content'][i1]['content'][i2]['content'][i3]['content'][3]['value']\n",
    "                    syst=data['content'][i1]['content'][i2]['content'][i3]['content'][4]['value']\n",
    "                    hist.SetBinContent(i1+1,i2+1,i3+1,nom)\n",
    "                    hist_stat.SetBinContent(i1+1,i2+1,i3+1,nom)\n",
    "                    hist_stat.SetBinError(i1+1,i2+1,i3+1,stat)\n",
    "                    hist_syst.SetBinContent(i1+1,i2+1,i3+1,nom)\n",
    "                    hist_syst.SetBinError(i1+1,i2+1,i3+1,syst)\n",
    "        return hist,hist_stat,hist_syst\n",
    "        \n",
    "    def JSONtoROOT(self):\n",
    "        hist={}\n",
    "        hist_stat={}\n",
    "        hist_syst={}\n",
    "        for iS in range(self.nScheme):\n",
    "            if self.nInputs[iS]==2:\n",
    "                hist[iS],hist_stat[iS],hist_syst[iS]=self.__GetHist2D(iS)\n",
    "            elif self.nInputs[iS]==3:\n",
    "                hist[iS],hist_stat[iS],hist_syst[iS]=self.__GetHist3D(iS)\n",
    "            else:\n",
    "                print(\"Number of inputs {0} not correct!!!\".format(self.nInputs[iS]))\n",
    "                return\n",
    "        \n",
    "        f_out=rt.TFile(self.file_name.replace(\"json\",\"root\"),\"recreate\")\n",
    "        for iS in range(self.nScheme):\n",
    "            hist[iS].Write()\n",
    "            hist_stat[iS].Write()\n",
    "            hist_syst[iS].Write()\n",
    "        f_out.Write()\n",
    "        f_out.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgSF=TrgSF(\"Efficiencies_muon_generalTracks_Z_Run2016_UL_HIPM_SingleMuonTriggers_schemaV2.json\")\n",
    "trgSF.JSONtoROOT()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
